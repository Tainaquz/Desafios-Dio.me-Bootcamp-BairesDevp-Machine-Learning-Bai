{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOopQWPalzZ7fBFoP6aBWuc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tainaquz/Desafios-Dio.me-Bootcamp-BairesDevp-Machine-Learning-Bai/blob/main/Desafio_Matriz_de_confus%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A primeira parte do Código foi retirado do video do desafio do Dio.me - Bootcamp BairesMachine Learning, objetivo do código após gerar a matriz de confusão, calcular as metricas sensitidade, especialidade, precisão, acuracia, fscore"
      ],
      "metadata": {
        "id": "HAx5ruWu6UMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bibliotes utilizadas\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Carregamento e pré-processamento do dataset MNIST\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "# 2. Construção do modelo CNN\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilação do modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Treinamento do modelo\n",
        "model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "previsao = model.predict(test_images)  # Previsões em probabilidade\n",
        "previsao_classes = np.argmax(previsao, axis=1)  # Converte para classes inteiras (0 a 9)\n",
        "\n",
        "# Cálculo da matriz de confusão\n",
        "matriz_confusao = tf.math.confusion_matrix(labels=test_labels, predictions=previsao_classes).numpy()\n",
        "\n",
        "# Normalização da matriz de confusão\n",
        "matriz_confusao_normalizada = np.around(matriz_confusao.astype('float') / matriz_confusao.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "# Conversão df\n",
        "matriz_confusao_df = pd.DataFrame(matriz_confusao_normalizada, index=classes, columns=classes)\n",
        "\n",
        "# plotar grafico\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(matriz_confusao_df, annot=True, cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('Rotulo verdadeiro')\n",
        "plt.xlabel('Previsao do rotulo ')\n",
        "plt.title('Normalizada Matriz de confusão')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX1vTCN56Ck2",
        "outputId": "a9503f93-4f19-47af-9b96-f4126b38e25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m 664/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 30ms/step - accuracy: 0.8094 - loss: 0.6049"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#desafio calcular a senstividade, previsão, especialidade, acuracia e f1_score\n",
        "#extraindo\n",
        "vp = np.diag(matriz_confusao)\n",
        "fp = np.sum(matriz_confusao, axis=0) - vp\n",
        "fn = np.sum(matriz_confusao, axis=1) - vp\n",
        "vn = np.sum(matriz_confusao) - (vp + fp + fn)\n",
        "#calculando metricas globais\n",
        "sensitividade = recall_score(test_labels, previsao_classes, average='macro')\n",
        "especificidade = np.mean(vn / (vn + fp))\n",
        "acuracia = accuracy_score(test_labels, previsao_classes)\n",
        "precisao = precision_score(test_labels, previsao_classes, average='macro')\n",
        "f1 = f1_score(test_labels, previsao_classes, average='macro')\n",
        "print(' Sensitividade:', sensitividade)\n",
        "print('Especificidade:', especificidade)\n",
        "print('Acurácia:', acuracia)\n",
        "print('Precisão:', precisao)\n",
        "print('F_Score:', f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u88KLpS70TJ",
        "outputId": "b2639a3f-707e-40bb-ffa0-1039fe39fb5c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sensitividade: 0.9896690002963557\n",
            "Especificidade: 0.9988650004809987\n",
            "Acurácia: 0.9898\n",
            "Precisão: 0.9899186637780758\n",
            "F_Score: 0.989779749241611\n"
          ]
        }
      ]
    }
  ]
}